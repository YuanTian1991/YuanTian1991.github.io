{
    "componentChunkName": "component---src-templates-note-template-js",
    "path": "/notes/Coursera---Regression-Models",
    "result": {"data":{"markdownRemark":{"html":"<p>I am following the <a href=\"https://www.coursera.org/learn/regression-models\">Regression Model Course on Coursera</a>. This note is just a collection of high-dense knowledge I absorbed from the course, and my understanding/key-code .etc. A super-mini summary. Also, One book I should read along with the course is <a href=\"https://leanpub.com/regmods\">this one</a> (maybe later one day ðŸ˜…), which can be freely downloaded.</p>\n<p>Why we still need to learn regression in nowadays where machine learning (ML) is surging up? One key advantage of regression against machine learning is the highly interpretable model fits.</p>\n<h2>Some types of Regressions</h2>\n<p>Three common concepts: <strong>Least Squares Regression (LSR)</strong>, <strong>Multivariable Regression (MVR)</strong> and <strong>Generalized Linear Models (GLM)</strong>. The difference between them is subtle:</p>\n<ul>\n<li><code class=\"language-text\">Least Squares Regression</code> seems most commonly represents the situation fitting one dependent variable (y) with one independent variable (x) with a <strong>straight line</strong>. The key is to find the minium residual (quite intuitive). I personally think this principle also works even if we have multiple x, however, according to some posts like <a href=\"https://www.real-statistics.com/multiple-regression/least-squares-method-multiple-regression/\">this</a> and <a href=\"https://stats.stackexchange.com/a/2363\">this</a>, if there are multiple x but only one y in a Least Squares Regression, it should be called as \"Multiple Regression\"...</li>\n<li><code class=\"language-text\">MultiVariable Regression</code> seems to represent the situation that there are multiple dependent and 1-N independent variables, when compared with the Multiple Regression concept above.</li>\n<li><code class=\"language-text\">Generalized Linear Models</code> seems like it could represent other models more than straight lines, for example, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>b</mi><mn>1</mn></msub><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>âˆ—</mo><mn>3...</mn></mrow><annotation encoding=\"application/x-tex\">y = b_1x_1^2 + b_2x_2*3...</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0622159999999998em;vertical-align:-0.24810799999999997em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">âˆ—</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3...</span></span></span></span></span>. According to ChatGPT, GLM does not require data distributions, normalisation .etc, which I am not sure about yet...</li>\n</ul>\n<hr>\n<p>To be continued...</p>","frontmatter":{"date":"December 31, 2022","slug":"/notes/Coursera---Regression-Models","title":"Coursera - Regression Models","tags":["Coursera","Regression","R"],"abstract":"Regression is am important tool that I should have dug into years ago. Here are just some key notes I write done during my learning with the Coursera course Regression Model."}}},"pageContext":{"slug":"/notes/Coursera---Regression-Models"}},
    "staticQueryHashes": ["63159454"]}